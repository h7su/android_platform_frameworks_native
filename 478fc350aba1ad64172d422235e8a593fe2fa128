{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "f9e9e77f_9b5960cb",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1010103
      },
      "writtenOn": "2022-07-07T19:23:29Z",
      "side": 1,
      "message": "I\u0027m confused on the value of this API. It looks to just do a readInt and then verify that elementSize * count is \u003c 1MB. But the 1MB is kinda arbitrary (and questionable - who said this Parcel came over Binder in the first place?)\n\nBut also it looks like something a simple helper could just as easily do, not something AParcel needs to provide?\n\nAlso since there\u0027s an extra readInt here, is there a missing write-equivalent of this?",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d686914e_f499ee68",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1944405
      },
      "writtenOn": "2022-07-07T21:08:06Z",
      "side": 1,
      "message": "The 1MB is related to the buffer size as mentioned by Steven\u0027s comment on line #1222, and it\u0027s matching the write from the writeVector call (linked below). \n\nThe Parcel could indeed not come from Binder, but we\u0027d still want to avoid allocating a very large chunk of RAM and have a chance of running OOM leading to crashes. If there\u0027s a case where this is needed in a non-binder context, we could approach that problem once it presents itself. The concern right now would be to have matching API calls and safe behavior for binder usage.\n\nAs for the \"write-equivalent\", it\u0027s in writeVector. \nhttps://cs.android.com/android/platform/superproject/+/master:frameworks/native/libs/binder/ndk/include_cpp/android/binder_parcel_utils.h;l\u003d1016?q\u003dbinder_parcel_utils.h\u0026ss\u003dandroid%2Fplatform%2Fsuperproject",
      "parentUuid": "f9e9e77f_9b5960cb",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "241f8911_6628e003",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1010103
      },
      "writtenOn": "2022-07-07T21:15:32Z",
      "side": 1,
      "message": "\u003e As for the \"write-equivalent\", it\u0027s in writeVector\n\nwriteVector does writeInt32(data_lenght) followed by writing the data.\n\nThis looks like it\u0027ll be a readInt32 of the datalenght for this validation followed by... what? If you do a readVector you\u0027ll end up with 2x readInt32\u0027s, which doesn\u0027t match the write side. What\u0027s the next step to actually getting the data?\n\n\u003e The Parcel could indeed not come from Binder, but we\u0027d still want to avoid allocating a very large chunk of RAM and have a chance of running OOM leading to crashes.\n\nBut that allocation already happened, it\u0027s already in the Parcel? If I already have a Parcel with a, say, 2MB array in it, then the blocker won\u0027t be on reading that vector. I\u0027m not quite getting what this solves? It\u0027s already in my process, I\u0027m already paying for it, what\u0027s the value in just not letting me access it?\n\nA *write* version of this to avoid creating an overly large Parcel sounds like it could have value, but the *read* side doesn\u0027t seem like it helps?\n\n\u003e If there\u0027s a case where this is needed in a non-binder context, we could approach that problem once it presents itself.\n\nThat doesn\u0027t really work for stable APIs as applications need to run on existing versions of this code. If this is instead a helper that the AIDL generator spits out or whatever *then* you can easily do the evolution you\u0027re talking about. But once this goes into a stable API surface, changing its behavior down the road becomes a lot more challenging.",
      "parentUuid": "d686914e_f499ee68",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b167d4d8_518b4e45",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1944400
      },
      "writtenOn": "2022-07-07T21:46:15Z",
      "side": 1,
      "message": "\u003e It\u0027s already in my process, I\u0027m already paying for it, what\u0027s the value in just not letting me access it?\n\nThe parcel might not actually be that big. I think we want to guard against malicious parcels and/or bugs where a vector is suppose to be at this position, but something else is present, resulting in an incorrect vector size that is large enough to kill the receiving process.\n\nNot related to the API design, but instead of checking against 10MB, maybe we could check against the remaining parcel size as a more flexible sanity check.",
      "parentUuid": "241f8911_6628e003",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ee1ba69b_62d2d0ed",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1010103
      },
      "writtenOn": "2022-07-07T21:59:05Z",
      "side": 1,
      "message": "The existing read array APIs already validate that the length doesn\u0027t exceed the remaining data, though, so a new API isn\u0027t needed for that? See ReadAndValidateArraySize in parcel.cpp.",
      "parentUuid": "b167d4d8_518b4e45",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a35a32fc_37e44c16",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1944405
      },
      "writtenOn": "2022-07-07T23:36:24Z",
      "side": 1,
      "message": "\u003e This looks like it\u0027ll be a readInt32 of the datalenght for this validation followed by... what? If you do a readVector you\u0027ll end up with 2x readInt32\u0027s, which doesn\u0027t match the write side. What\u0027s the next step to actually getting the data?```\n\nI see what you\u0027re saying. The data can still be retrieved, however a call to AParcel_setDataPosition is required between `resizeVector` call and `readVector` call.\n\n\u003e The existing read array APIs already validate that the length doesn\u0027t exceed the remaining data, though, so a new API isn\u0027t needed for that? See ReadAndValidateArraySize in parcel.cpp.```\n\nThe idea here is to delegate the call to binder parcel, as mentioned in the bug. ReadAndValidateArraySize is local to parcel.cpp, not in the ndk. I might be misunderstanding something, if so, please let me know. \n\n\n-----\nWould you have an example of a Parcel not coming from Binder where size might also exceed the limitation?",
      "parentUuid": "ee1ba69b_62d2d0ed",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0f535784_ffb2e16f",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1010103
      },
      "writtenOn": "2022-07-07T23:56:51Z",
      "side": 1,
      "message": "\u003e The data can still be retrieved, however a call to AParcel_setDataPosition is required between  resizeVector  call and  readVector  call.\n\nThis seems like not a great API design then? At a minimum that needs to be documented since it makes this a very error prone API as-is.\n\n\u003e ReadAndValidateArraySize is local to parcel.cpp, not in the ndk.\n\nAll the AParcel_read*Array calls use that function before they try to allocate anything. Meaning it\u0027s already not possible to get an array back that\u0027s bigger than the size of the parcel. So the only thing this API does is add an arbitrary 1MB limit. That doesn\u0027t seem like a good API to me. As a user I can already just have whatever arbitrary limits I want, I don\u0027t need libbinder_ndk to do that (and I probably don\u0027t want libbinder_ndk to do that, either)\n\nSo I think the bug is wrong. The fix here seems like it\u0027s to just make AParcel_resizeVector to use a combination of AParcel_getDataPosition() and AParcel_getDataSize() to allocating something larger than the remaining payload, the same way that all the AParcel_read*Array\u0027s do. At that point whether or not you also want to have an additional size limit is up to you, but there\u0027s no reason to enshrine that in libbinder\u0027s NDK API surface.\n\n\u003e Would you have an example of a Parcel not coming from Binder \n\nAny in-process usage of Parcel? It\u0027s not going to be very common, but it\u0027s definitely not banned or prevented in any way. AIDL supports an in-process pass-through mode for a reason, things use it. None of those will hit any binder IPC limits.",
      "parentUuid": "a35a32fc_37e44c16",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0efdbf9e_2a21b833",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1120458
      },
      "writtenOn": "2022-07-08T00:24:59Z",
      "side": 1,
      "message": "Alright :) hi!\n\n- (I might have forgotten this detail and misrepresented in the CTS CL) ReadAndValidateArraySize is a separate case. This API is used when reading out arrays (the client requests an array and then passes it to code to fill out. Since the array isn\u0027t represented on the Parcel, we need a way to limit allocations). This is different than readVector/writeVector which writes the whole vector.\n- there is no setDataPosition required here or to use this API. Elie is saying this because I misremembered about readVector/writeVector.\n- this is already a limit we have here, and this CL is moving it into the framework\n\nAs far as in-process usages of Parcel, if a Parcel is corrupted or reads are misaligned, allocating something 2GB and getting OOM is not a good result. Generally if we have code using Parcel, we want it to work in- and out- of process. So adhering to the binder limits makes the code portable. This is also why RPC binder adds arbitrary limits. If even 1MB of data is being parceled in-process, the user of the code is doing something incorrect - this is an inappropriate amount of data to copy multiple times. If there is a user that really does need this, we will be eager to support them, but most likely it will be by telling them not to do this thing.",
      "parentUuid": "0f535784_ffb2e16f",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8f2f8953_2396553d",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1010103
      },
      "writtenOn": "2022-07-08T15:21:48Z",
      "side": 1,
      "message": "\u003e this is already a limit we have here, and this CL is moving it into the framework\n\nBut that\u0027s the issue, the \"moving it into framework\" is the part that I\u0027m objecting to. This type of policy really doesn\u0027t belong in the API surface. The policy is fine for the AIDL generator if that\u0027s what it wants to do, but AParcel itself shouldn\u0027t be doing such a thing.\n\nAlso there\u0027s really no benefit to being in framework anyway. The enforcement of this limit is *easier* to do without this API than it is with the API. So we shouldn\u0027t be paying the complexity for an API here when the existing 1 line if check in binder_parcel_utils does the same thing.\n\nIf we\u0027re ever in a position to change the 1MB binder IPC limit, we can revisit how to expose that. But there\u0027s only downsides to adding this API as far as I can tell.\n\n\u003e So adhering to the binder limits makes the code portable. This is also why RPC binder adds arbitrary limits. If even 1MB of data is being parceled in-process, the user of the code is doing something incorrect \n\nHaving such a limit on the *write* side I can see, but this is on the *read* side. The cost has already been paid at this point, kinda late to try and enforce anything?",
      "parentUuid": "0efdbf9e_2a21b833",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "67fb31e5_739cbeb8",
        "filename": "libs/binder/ndk/include_ndk/android/binder_parcel.h",
        "patchSetId": 6
      },
      "lineNbr": 1222,
      "author": {
        "id": 1944405
      },
      "writtenOn": "2022-07-08T19:09:02Z",
      "side": 1,
      "message": "\u003e Having such a limit on the *write* side I can see, but this is on the *read* side. The cost has already been paid at this point, kinda late to try and enforce anything?\n\nI do believe the check on the *read* side would still be beneficial for stability. Enforcing on the *write* side does make sense, however there is no guarantee that the Parcel or contents of that Parcel do not get corrupt. If the Parcel or vector does get corrupted, the 1MB enforcing done by the *write* side does not hold anymore, at which point there\u0027s a chance of an attempt to allocate a vector large enough to run OOM.",
      "parentUuid": "8f2f8953_2396553d",
      "revId": "478fc350aba1ad64172d422235e8a593fe2fa128",
      "serverId": "85c56323-6fa9-3386-8a01-6480fb634889"
    }
  ]
}